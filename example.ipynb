{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "\n",
    "import maelstrom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, set up data loader. This will provide a tf.dataset object that can be used for training. The loader has many options that influence how data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"Predictor shape\": \"10, 32, 32, 14\",\n",
      "    \"Target shape\": \"10, 32, 32, 1\",\n",
      "    \"Num files\": 9,\n",
      "    \"Samples per file\": 1,\n",
      "    \"Patches per sample\": 16,\n",
      "    \"Num patches\": 144,\n",
      "    \"Patch size\": 32,\n",
      "    \"Num leadtimes\": 10,\n",
      "    \"Batch size\": 1,\n",
      "    \"Num predictors\": 14,\n",
      "    \"Num targets\": 1,\n",
      "    \"Predictors\": [\n",
      "        \"air_temperature_0.1_2m\",\n",
      "        \"air_temperature_0.9_2m\",\n",
      "        \"air_temperature_2m\",\n",
      "        \"bias_yesterday\",\n",
      "        \"cloud_area_fraction\",\n",
      "        \"precipitation_amount\",\n",
      "        \"x_wind_10m\",\n",
      "        \"y_wind_10m\",\n",
      "        \"altitude\",\n",
      "        \"analysis_std\",\n",
      "        \"bias_recent\",\n",
      "        \"land_area_fraction\",\n",
      "        \"model_altitude\",\n",
      "        \"model_laf\"\n",
      "    ],\n",
      "    \"Patch size (MB)\": 0.5859375,\n",
      "    \"Total size (GB)\": 0.0823974609375\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "input_filenames = glob.glob(\"data/air_temperature/5GB/2020030*T*Z.nc\")\n",
    "loader = maelstrom.loader.FileLoader(filenames=input_filenames,\n",
    "    patch_size=32,   # Break the grid into 32x32 squares to increase the number of samples\n",
    "    # limit_leadtimes=[0, 12, 24],  # Only load these leadtimes\n",
    "    # limit_predictors=[\"air_temperature_2m\", \"wind_speed_10m\"], # Only load these predictors\n",
    "    # x_range=0:12, # Only load the first 12 columns of the grid\n",
    "    # y_range=0:10, # Only load the first 10 columns of the grid\n",
    "    predict_diff=True, # Change the target to be the difference between the target and raw forecast\n",
    "    cache_size=100,  # How many files should be stored in memory between epochs\n",
    "    prefetch=1\n",
    ")\n",
    "print(loader)\n",
    "input_shape = loader.predictor_shape\n",
    "num_outputs = loader.num_targets\n",
    "\n",
    "dataset = loader.get_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the model for training. Either use a predefined model from `maelstrom.models` or create one using the keras interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = maelstrom.loss.mae\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1.0e-2)\n",
    "\n",
    "model = maelstrom.models.BasicBenchmark(input_shape, num_outputs)\n",
    "model.compile(optimizer=optimizer, loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "    138/Unknown - 42s 296ms/step - loss: 9.6469"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=2)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model on independent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 1s/step - loss: 2.7284\n",
      "2.728421449661255\n"
     ]
    }
   ],
   "source": [
    "input_filenames = glob.glob(\"data/air_temperature/5GB/2021030*T*Z.nc\")\n",
    "val_loader = maelstrom.loader.FileLoader(filenames=input_filenames)\n",
    "val_dataset = val_loader.get_dataset()\n",
    "\n",
    "results = model.evaluate(val_dataset)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
